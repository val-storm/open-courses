Artificial Intelligence and Machine Learning 
Module 02: Bias

Open vs Closed Source Data?
    - we cant analyze what we can't read
    - social impact but no accountability
What controversial ML is out there?
    - short listing college applicants
    - sentencing people convicted of crimes
    - candidates for jobs
The idea that if a Machine Learned it, than it much be right.
    -  The Jared Problen
Asking the right questions, framing them right, having data that actually represents the problem
    -find examples
What is a "problem"?
The effects of the failures of Bias
    - categorizing based off of biological sex, why do they need to know?
    - recreating bias not learning categorical imperatives
    - viewing technology as not for you
    - creating distancing instances

The human use of human beings? Positive feedback loops, and self fulfilling prophecy?

Can machine learning give us new way of thinking about things? Or merely reflect what we already know? Facial recognition is essentially doing what we know how to do already, which is, identify a face in a digital representation of a photograph. It's just doing it quickly and reporting data about the location and what not... 

if we limit a scope of a problem to 2 dimensions we only see a circle when in 3 dimensions it would be a cylinder... 

so when data is used that is missing a dimension, are we just seeing circles instead of cyclinders?

What if I told you that machine learning is used to sort through lists of candidtates for jobs and entrance into university? what if I told you that machine learning is used to decide if people arrested for alleged crimes should get bail before their trial or even their sentence if convicted? What if I told you that machine learning has been found time and time again to be altogether problematic in its ever widening use in policy and social contexts? I would not be lying. In fact the greivances against "AI" used in social contexts range from the tragic, to the infuriating to downrigt shameful.

But first, let's look at what we are talking about here...

In our last video we took a very zoomed out view of a facial recognition technique where we labeled the regions of digital pictures as having a face in them. Thus training our model to hopefully recognize faces. 

Every machine learning framework is going to need some type of input to produce an output. In most cases, the input will be similar to the training data, the only deifference being that training data is labeled with the correct "answer" or the correct "output". So after seeing thousands of correct answers, a trained machine learning model can then to a very high degree of accuracy guess what the output of unlabeled input would be.

If you're wondering about our machine learning algorithm mystery box, all that's going on in here is a lot of linear algebra, some calculus which if you those words get you MORE curious then check the resources for this module to find some helpful links on the subject. To put it poetically, inside this box is some math that allows the data to make impressions in memory that result in something akin to a sorting "mechanism".  

There are many different algorithms and this is definitely a bit generalizing, but for most of this class we will keep a very birds eye view and point you to places to further your understanding if you should wish

(input and output, are we done??)

looking back at some of these use cases mentioned at the begining let's look closer at the inputs and outputs. in many cases the data for whether someone should get an interview, get bail, get a maximum sentence, or be admitted to a school is soured from historical data. this historical data has been generated by humans making decisions on previous situations. it would be great to believe that all of these decisions have been made without any bias from those responsible for deciding who to interview, who to grant bail, whom to accept to the program, but this is not always the case. therefore when you train machine learning algorithms on already biased historical data, your machine is gauranteed to recreate any bias present in the training data. so, if your company generally hires candidates with striking similarities, your ML is likely to keep suggesting whatever homogenity surfaces from your practices.

This is a big deal, and once again, there are far too many instances of major bias being found in algorithms used by huge businesses, governments and schools and these have a major impact on peoples lives, this can't be stressed enough. So, why are they still in use? 

Pro publica study on judicial algorithm
University where they went back and granted admission to those passed up

Historical data is only one way machine learning can be biased. As mentioned in the first video, there are instances of "researchers" training facial recognition systems to guess what genetalia they have or who their preffered sexual partners are all from images of their face. And while you might think that's twisted, advertising companies might think it's worth the investment so they can know how and what to market to people. And like in the case of Target using customer data to predic if a customer was pregnant and selling the information, they are totally legaly allowed to do so, becuase they never asked the person in question, they just inferred the information, so they aren't violating any privacy policy.... And there's more... other instances where it creeps in and that's in real time suggestions and crowd sourced information like auto complete, and other types of suggestions online. Did you know that 

facebook swimsuit photos, linked in, 

it's not so inevitable that AI will rise up and overthrow the human race as people like to foment in the news but that the positive feedback loops created by poorly planned and unethically maintained AI would limit all possibilites for growth and change, and people not being judged by some irrelevant data point that "puts them generally in a category" becuase that's the category some people place them in. 

facebook pictures search, amazon suggestions

Now what are we going to do about that?



ever since before machine learning has been around it has been plagued by bias
input and output <-- intro topic